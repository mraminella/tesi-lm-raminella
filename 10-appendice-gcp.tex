\chapter{Tecnologie utilizzate}\label{appendice}
\section{Google Cloud Platform}
L'intero progetto presentato in questo documento è stato realizzato sfruttando tecnologie della Google Cloud Platform, in modo di sfruttare la potenza computazionale messa a disposizione di Google Cloud. Ogni tecnologia è ottimizzata a uno scopo specifico, qui verranno descritte in maniera estremamente sintetica i principali prodotti utilizzati. Per ciascun progetto si può disporre di un macro raccoglitore che consente di raccogliere tutte le fatturazioni dei consumi effettuati facendo uso dei prodotti per esso.
\subsection{BigQuery}\label{bigquery}
BigQuery è un data warehouse cloud veloce a elevata scalabilità. È realizzato su una piattaforma serverless, in assenza di un'infrastruttura da gestire. Offre tutte le operazioni CRUD di un database classico, in combinazione a operatori aggiuntivi. Tali operazioni possono eseguite su quantità estremamente grandi in quanto il sistema è ottimizzato per avere alto throughput. È stato introdotto recentemente Bigquery ML che mette a disposizione anche operatori mirati direttamente alla realizzazione di modelli predittivi su dati tabellari.
\subsection{Google Cloud Storage}\label{gcs}
Google Cloud Storage (GCS) è una piattaforma di storage in cloud basata sul filesystem di Hadoop. Si può realizzare un \textit{bucket} GCS, che rappresenta l'astrazione di un singolo disco. Il bucket è accessibile dall'URI \texttt{gs://nome-bucket/} attraverso le API messe a disposizione. Come il filesystem di Hadoop, è ottimizzato per le operazioni write-once, read-many: sono supportate la scrittura, la lettura e l'eliminazione, ma non lo spostamento diretto di file o cartelle: l'interfaccia utente esegue gli spostamenti tramite una copia seguita dall'eliminazione dalla posizione di partenza.
Sono offerti diversi piani tariffari, sulla base dell'allocazione geografica e della frequenza di accesso richieste. Nel caso in cui si volesse effettuare un backup, ad esempio, si può scegliere di realizzare un bucket con un piano a basso costo di stoccaggio ma alto costo di trasferimento.
\subsection{Compute Engine}\label{computengine}
Compute Engine rappresenta una piattaforma di virtualizzazione in cloud. Si possono realizzare le singole macchine virtuali, configurare la potenza della singola macchina, capacità di memoria, presenza o meno di scheda video, tipi e dimensione dei dischi, eccetera. Si dispone anche di una pratica interfaccia di collegamento diretto in SSH a ciascuna macchina. In un progetto Google Cloud Platform si hanno dei limiti massimi sul numero di processori a disposizione, dato che Compute Engine è integrato con Dataflow la scalabilità massima è determinata da tale limite. Il costo di una macchina è determinato dalla taglia di processore, di RAM e dalla presenza di schede video (fino a 8) e viene tariffato per tempo di accensione.
\img{Imgs/computengine1.png}{GCP Compute Engine, schermata di dimensionamento personalizzato macchina. Oltre a una collezione di modelli predefiniti, è possibile scegliere il dimensionamento dei singoli componenti di una macchina. Compute Engine allocherà le risorse richieste sull'hardware a disposizione di Google Cloud.}{img:computengine1} Una macchina spenta può essere ridimensionata a piacere, per adeguare le risorse al carico richiesto da una certa applicazione, qualora si trovasse in uno stato di carico eccessivo o, viceversa, ridotto. In questo ultimo caso, Compute Engine suggerisce direttamente di ridimensionare le macchine che non utilizzano buona parte del proprio carico, in modo di ridurre sia i costi che gli sprechi, dal momento che una macchina allocata e accesa senza essere utilizzata sta sprecando risorse preziose.
\img{Imgs/computengine2.png}{GCP Compute Engine, schermata di suggerimento ridimensionamento istanza. Per ogni istanza sottoutilizzata, viene suggerito un possibile ridimensionamento per allineare la capacità della macchina al suo carico delle ultime ore. }{fig:computengine2}
\subsection{Google Dataflow}\label{dataflow}
Dataflow permette di lanciare in esecuzione le pipeline di processamento dati facendo uso della capacità computazionale disponibile su Compute Engine. Esso gestirà autonomamente il carico e tutto il processo di creazione e distruzione di macchine virtuali realizzate al solo scopo di scalare dinamicamente la computazione. Per ogni singola pipeline si possono avere metriche accurate sulla quantità di dati processati e sui consumi. Per ogni singolo stadio della pipeline è possibile conoscere il numero di elementi processati, ottenere il log relativo ad essa ed eseguire ricerche avanzate su di esso. In questo modo si ottiene un alto controllo su flussi complessi con molte fasi di processamento e si possono individuare criticità su possibili casi isolati. Spesso infatti ci potrebbero essere degli \textit{outlier} sui dati non considerati in precedenza, non essendo possibile analizzare ogni singolo record della sorgente che viene processata. Questi outlier potrebbero essere, per esempio, caratterizzati da valori al di fuori di un dominio considerato valido per un particolare campo che viene trasformato.
\subsection{Piattaforma IA}\label{mlengine}
La Piattaforma IA, precedentemente chiamata MLEngine, è nata per eseguire il training su cloud dei modelli realizzati con Tensorflow e disporre il provisioning dei modelli funzionanti in modo di renderli accessibili da qualunque dispositivo connesso. Dato che anche Tensorflow è un prodotto Google, la Piattaforma IA ruota intorno ad esso e cresce rapidamente allo stesso modo, sono stati resi a disposizione il Hub IA, ricco di materiali condivisi fra la community, integrato con i Notebook. Questi ultimi sono direttamente derivati da Jupyter Notebook, il valore aggiunto è dato dal fatto che il motore Python viene eseguito direttamente su una macchina virtuale in cloud e non è necessario installare alcun server. Inoltre la capacità di computazione delle macchine messe a disposizione sui Notebook di IA Hub è gratuita e non prevede tariffazione. Un altro strumento a disposizione è l'interfaccia di etichettatura (labeling) dei dati.
\img{Imgs/iahub.png}{Piattaforma IA, menu laterale: sono mostrati tutti gli strumenti messi a disposizione. Su Hub IA si può accedere ai notebook condivisi dalla comunità di sviluppatori Tensorflow. Su Etichettatura dati si hanno strumenti utili per il labeling dei dati. In Notebook si possono creare e lanciare con supporto di macchine in cloud i Notebook in Python. Su Job si possono lanciare i training delle reti neurali e visualizzare lo stato e i risultati. Su Modelli si possono caricare i modelli di reti neurali dopo il training per renderli disponibili a qualunque applicativo.}{fig:iahub}
In questo progetto è stata utilizzata principalmente la parte di Job, dato che tutti i training sono stati eseguiti in cloud, in seguito alla preparazione dei dataset.
\section{Tensorflow e Tensorboard}\label{tensorboard}
Tensorflow è un framework realizzato da Google allo scopo di implementare le reti neurali. Le sue API sono in costante cambiamento, in particolare è in corso la transizione da Python 2.7 alla versione 3, dato che entro fine anno verrà deprecata \cite{python2sunsetting}. Mentre nelle prime versioni era necessario implementare manualmente i singoli neuroni con i relativi ingressi rappresentati sotto forma di oggetti tensori, dove un tensore è la singola connessione fra un ingresso, neurone e/o uscita. Ora sono disponibili primitive per la realizzazione di strati già noti in letteratura, ad esempio strati fully connected, convoluzionali, ricorrenti, eccetera. Una volta che è stata realizzata la rete ed eseguito il training, è necessario valutare la bontà dei risultati ottenuti, attraverso la valutazione delle metriche raccolte, come la loss (che determina l'entità di variazione del peso nei singoli tensori), il MAE (visto su \ref{training}), la matrice di confusione, eccetera.
Tensorboard è lo strumento principale attualmente utilizzato per avere una valutazione delle metriche ottenute in seguito ai training effettuati su Tensorflow. Ogni singola metrica ottenuta è visualizzabile nel progresso di tutto il training. Sulla base di come sono state aggiunte metriche di valutazione all'architettura della rete si possono avere visualizzazioni più o meno dettagliate.